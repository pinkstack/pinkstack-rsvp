akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "INFO"
  loglevel = ${?AKKA_LOG_LEVEL}

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    // debug.receive = true
  }

  # Configuration for Kafka
  kafka {
    producer {

      # Tuning parameter of how many sends that can run in parallel.
      parallelism = 100

      # Duration to wait for `KafkaConsumer.close` to finish.
      close-timeout = 60s

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the producer stages. Some blocking may occur.
      # When this value is empty, the dispatcher configured for the stream
      # will be used.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
      eos-commit-interval = 100ms

      # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
      # can be defined in this configuration section.
      kafka-clients {
      }
    }

    consumer {
      # Tuning property of scheduled polls.
      poll-interval = 50ms

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that blocking of the thread that
      # is executing the stage will be blocked.
      poll-timeout = 50ms

      # The stage will be await outstanding offset commit requests before
      # shutting down, but if that takes longer than this timeout it will
      # stop forcefully.
      stop-timeout = 30s

      # How long to wait for `KafkaConsumer.close`
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `TimeoutException`.
      commit-timeout = 15s

      # If the KafkaConsumer can't connect to the broker the poll will be
      # aborted after this timeout. The KafkaConsumerActor will throw
      # org.apache.kafka.common.errors.WakeupException which will be ignored
      # until max-wakeups limit gets exceeded.
      wakeup-timeout = 3s

      # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
      max-wakeups = 10

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # Disable auto-commit by default
        enable.auto.commit = false
      }
    }

    testkit {
      testcontainers {

        # define this to select a different Kafka version by choosing the desired version of Confluent Platform
        # available Docker images: https://hub.docker.com/r/confluentinc/cp-kafka/tags
        # Kafka versions in Confluent Platform: https://docs.confluent.io/current/installation/versions-interoperability.html
        confluent-platform-version = "5.4.1"

        # the number of Kafka brokers to include in a test cluster
        num-brokers = 1

        # set this to use a replication factor for internal Kafka topics such as Consumer Offsets and Transaction log.
        # this replication factor must be less than or equal to `num-brokers`
        internal-topics-replication-factor = 1
      }
    }
  }
}